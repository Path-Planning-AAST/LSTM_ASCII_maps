Log file created at: 2018/03/07 15:42:11
Running on machine: LEONIDA
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0307 15:42:11.282692 10507 TestNeuralNetwork.cpp:121]  steps tail size: 1
I0307 15:42:12.580008 10507 TestNeuralNetwork.cpp:243] Allowed DIAGONAL directions
I0307 15:42:12.580042 10507 TestNeuralNetwork.cpp:251] Paths composing datasets will have maximum 300 steps
I0307 15:42:12.774968 10507 TrainVal_db.cpp:78] GPU mode
I0307 15:42:12.774998 10507 TrainVal_db.cpp:84] ../RecurrentNets/LSTM/deep_lstm_solver.prototxt
I0307 15:42:18.571203 10507 TrainVal_db.cpp:129] Net loaded: LSTM_stack-2-16
I0307 15:42:18.571211 10507 TrainVal_db.cpp:130] TRAIN INFO: batch size: 2048
I0307 15:42:18.571214 10507 TrainVal_db.cpp:131] Forward - backward per batch (gradients accumulated): 1
I0307 15:42:18.571216 10507 TrainVal_db.cpp:132] Number of updates per batch: 1
I0307 15:42:18.571219 10507 TrainVal_db.cpp:133] Unrolling for 10 timesteps
F0307 15:42:18.571633 10507 net.cpp:686] Check failed: target_blobs[j]->shape() == source_blob->shape() Cannot share param 0 weights from layer 'out'; shape mismatch.  Source param shape is 2 22 (44); target param shape is 8 22 (176)
