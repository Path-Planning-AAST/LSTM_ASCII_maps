Log file created at: 2018/03/07 15:41:45
Running on machine: LEONIDA
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0307 15:41:45.260635 10490 TestNeuralNetwork.cpp:121]  steps tail size: 1
I0307 15:41:46.559716 10490 TestNeuralNetwork.cpp:243] Allowed DIAGONAL directions
I0307 15:41:46.559753 10490 TestNeuralNetwork.cpp:251] Paths composing datasets will have maximum 300 steps
I0307 15:41:46.760435 10490 TrainVal_db.cpp:78] GPU mode
I0307 15:41:46.760450 10490 TrainVal_db.cpp:84] ../RecurrentNets/LSTM/deep_lstm_solver.prototxt
I0307 15:41:52.508693 10490 TrainVal_db.cpp:129] Net loaded: LSTM_stack-2-16
I0307 15:41:52.508702 10490 TrainVal_db.cpp:130] TRAIN INFO: batch size: 2048
I0307 15:41:52.508719 10490 TrainVal_db.cpp:131] Forward - backward per batch (gradients accumulated): 1
I0307 15:41:52.508721 10490 TrainVal_db.cpp:132] Number of updates per batch: 1
I0307 15:41:52.508725 10490 TrainVal_db.cpp:133] Unrolling for 10 timesteps
F0307 15:41:52.509289 10490 net.cpp:686] Check failed: target_blobs[j]->shape() == source_blob->shape() Cannot share param 0 weights from layer 'lstm1'; shape mismatch.  Source param shape is 64 1 (64); target param shape is 8 1 (8)
